{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "# backSub = cv2.createBackgroundSubtractorMOG2()\n",
    "backSub = cv2.createBackgroundSubtractorKNN()\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "    \n",
    "    fgMask = backSub.apply(frame)\n",
    "    \n",
    "    \n",
    "    cv2.rectangle(frame, (10, 2), (100,20), (255,255,255), -1)\n",
    "    cv2.putText(frame, str(cap.get(cv2.CAP_PROP_POS_FRAMES)), (15, 15),\n",
    "               cv2.FONT_HERSHEY_SIMPLEX, 0.5 , (0,0,0))\n",
    "    \n",
    "    \n",
    "#     cv2.imshow('Frame', frame)\n",
    "    cv2.imshow('FG Mask', fgMask)\n",
    "    \n",
    "    keyboard = cv2.waitKey(1)\n",
    "    if keyboard == ord('q') or keyboard == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "# backSub = cv2.createBackgroundSubtractorMOG2()\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, bgframe = cap.read()\n",
    "# cv2.imwrite(\"bg.png\",bgframe)\n",
    "# bgframe = cv2.imread(\"bg.png\")\n",
    "bgframe = cv2.cvtColor(bgframe, cv2.COLOR_BGR2GRAY)\n",
    "starwars = cv2.imread(\"beach.jpg\")\n",
    "starwars = cv2.resize(starwars,(640,480))\n",
    "# cv2.imshow(\"test\",bgframe)\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "    gray =  cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    mask = np.where((gray - bgframe)<=100,0,1)\n",
    "    inv_mask = 1 - mask\n",
    "    for c in range(3):\n",
    "        frame[...,c] = frame[...,c]*mask + starwars[...,c]*inv_mask\n",
    "    \n",
    "    cv2.imshow('Frame', frame)\n",
    "    \n",
    "    keyboard = cv2.waitKey(1)\n",
    "    if keyboard == ord('q') or keyboard == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Blur"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('get capabilities result', 0)\n",
      "('capabilities', '0x85208000')\n",
      "v4l2 driver: b'v4l2 loopback'\n"
     ]
    }
   ],
   "source": [
    "import pyfakewebcam\n",
    "import numpy as np\n",
    "import time\n",
    "import timeit\n",
    "import cv2\n",
    "import sys\n",
    "\n",
    "from PIL import Image\n",
    "\n",
    "def shift_image(img, dx, dy):\n",
    "    img = np.roll(img, dy, axis=0)\n",
    "    img = np.roll(img, dx, axis=1)\n",
    "    if dy>0:\n",
    "        img[:dy, :] = 0\n",
    "    elif dy<0:\n",
    "        img[dy:, :] = 0\n",
    "    if dx>0:\n",
    "        img[:, :dx] = 0\n",
    "    elif dx<0:\n",
    "        img[:, dx:] = 0\n",
    "    return img\n",
    "\n",
    "def hologram_effect(img):\n",
    "    # add a blue tint\n",
    "    holo = cv2.applyColorMap(img, cv2.COLORMAP_WINTER)\n",
    "    # add a halftone effect\n",
    "    bandLength, bandGap = 2, 3\n",
    "    for y in range(holo.shape[0]):\n",
    "        if y % (bandLength+bandGap) < bandLength:\n",
    "            holo[y,:,:] = holo[y,:,:] * np.random.uniform(0.1, 0.3)\n",
    "    # add some ghosting\n",
    "    holo_blur = cv2.addWeighted(holo, 0.2, shift_image(holo.copy(), 5, 5), 0.8, 0)\n",
    "    holo_blur = cv2.addWeighted(holo_blur, 0.4, shift_image(holo.copy(), -5, -5), 0.6, 0)\n",
    "    # combine with the original color, oversaturated\n",
    "    out = cv2.addWeighted(img, 0.5, holo_blur, 0.6, 0)\n",
    "    return out\n",
    "\n",
    "cam = pyfakewebcam.FakeWebcam('/dev/video2', 640, 480)\n",
    "cam.print_capabilities()\n",
    "\n",
    "cap = cv2.VideoCapture(0)\n",
    "\n",
    "#set the width and height\n",
    "# cap.set(3,1280)\n",
    "# cap.set(4,720)\n",
    "\n",
    "\n",
    "\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "    if ret==True:\n",
    "\n",
    "        frame = hologram_effect(frame)\n",
    "        cv2.imshow('frame',frame)\n",
    "        frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "        cam.schedule_frame(frame)\n",
    "        #show the captured frame\n",
    "       \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "# Release everything if job is finished\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "cap = cv2.VideoCapture(0)\n",
    "ret, bgframe = cap.read()\n",
    "cv2.imwrite(\"bg.png\",bgframe)\n",
    "bgframe = cv2.imread(\"bg.png\")\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('get capabilities result', 0)\n",
      "('capabilities', '0x85208001')\n",
      "v4l2 driver: b'v4l2 loopback'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyfakewebcam\n",
    "# backSub = cv2.createBackgroundSubtractorMOG2()\n",
    "cap = cv2.VideoCapture(0)\n",
    "# ret, bgframe = cap.read()\n",
    "# cv2.imwrite(\"bg.png\",bgframe)\n",
    "bgframe = cv2.imread(\"bg.png\")\n",
    "bgframe = cv2.cvtColor(bgframe, cv2.COLOR_BGR2GRAY)\n",
    "starwars = cv2.imread(\"beach.jpg\")\n",
    "starwars = cv2.resize(starwars,(640,480))\n",
    "# cv2.imshow(\"test\",bgframe)\n",
    "cam = pyfakewebcam.FakeWebcam('/dev/video2', 640, 480)\n",
    "cam.print_capabilities()\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "    gray =  cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    mask = np.where((gray - bgframe)<=140,0,1)\n",
    "    inv_mask = 1 - mask\n",
    "    for c in range(3):\n",
    "        frame[...,c] = frame[...,c]*mask + starwars[...,c]*inv_mask\n",
    "    cv2.imshow('Frame', frame) \n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    cam.schedule_frame(frame)    \n",
    "    \n",
    "    keyboard = cv2.waitKey(1)\n",
    "    if keyboard == ord('q') or keyboard == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cool background"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import js2py\n",
    "add = js2py.eval_js('function add(a, b) {return a + b}')\n",
    "add(1,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('get capabilities result', 0)\n",
      "('capabilities', '0x85208001')\n",
      "v4l2 driver: b'v4l2 loopback'\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import pyfakewebcam\n",
    "import requests\n",
    "\n",
    "bgframe = cv2.imread(\"bg.png\")\n",
    "bgframe = cv2.cvtColor(bgframe, cv2.COLOR_BGR2GRAY)\n",
    "starwars = cv2.imread(\"starwars.jpg\")\n",
    "starwars = cv2.resize(starwars,(640,480))\n",
    "cam = pyfakewebcam.FakeWebcam('/dev/video2', 640, 480)\n",
    "cam.print_capabilities()\n",
    "cap = cv2.VideoCapture(0)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if frame is None:\n",
    "        break\n",
    "    gray =  cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)\n",
    "    mask = np.where((gray - bgframe)<=140,0,1)\n",
    "    inv_mask = 1 - mask\n",
    "    for c in range(3):\n",
    "        frame[...,c] = frame[...,c]*mask + starwars[...,c]*inv_mask\n",
    "    cv2.imshow('Frame', frame) \n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    cam.schedule_frame(frame)    \n",
    "    \n",
    "    keyboard = cv2.waitKey(1)\n",
    "    if keyboard == ord('q') or keyboard == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "327044\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import requests\n",
    "import pyfakewebcam\n",
    "import pafy\n",
    "from datetime import datetime \n",
    "\n",
    "def putIterationsPerSec(frame, iterations_per_sec):\n",
    "    \"\"\"\n",
    "    Add iterations per second text to lower-left corner of a frame.\n",
    "    \"\"\"\n",
    "    cv2.putText(frame, \"{:.0f} iterations/sec\".format(iterations_per_sec),\n",
    "        (10, 20), cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255))\n",
    "    return frame\n",
    "\n",
    "class CountsPerSec:\n",
    "    \"\"\"\n",
    "    Class that tracks the number of occurrences (\"counts\") of an\n",
    "    arbitrary event and returns the frequency in occurrences\n",
    "    (counts) per second. The caller must increment the count.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        self._start_time = None\n",
    "        self._num_occurrences = 0\n",
    "\n",
    "    def start(self):\n",
    "        self._start_time = datetime.now()\n",
    "        return self\n",
    "\n",
    "    def increment(self):\n",
    "        self._num_occurrences += 1\n",
    "\n",
    "    def countsPerSec(self):\n",
    "        elapsed_time = (datetime.now() - self._start_time).total_seconds()\n",
    "        return self._num_occurrences / elapsed_time if elapsed_time > 0 else 0\n",
    "\n",
    "def get_mask(frame, bodypix_url='http://localhost:9000'):\n",
    "    _, data = cv2.imencode(\".jpg\", frame)\n",
    "    r = requests.post(\n",
    "        url=bodypix_url,\n",
    "        data=data.tobytes(),\n",
    "        headers={'Content-Type': 'application/octet-stream'})\n",
    "    mask = np.frombuffer(r.content, dtype=np.uint8)\n",
    "    mask = mask.reshape((frame.shape[0], frame.shape[1]))\n",
    "    return mask\n",
    "\n",
    "def post_process_mask(mask):\n",
    "    mask = cv2.dilate(mask, np.ones((5,5), np.uint8) , iterations=1)\n",
    "    mask = cv2.blur(mask.astype(float), (30,30))\n",
    "    return mask\n",
    "\n",
    "def shift_image(img, dx, dy):\n",
    "    img = np.roll(img, dy, axis=0)\n",
    "    img = np.roll(img, dx, axis=1)\n",
    "    if dy>0:\n",
    "        img[:dy, :] = 0\n",
    "    elif dy<0:\n",
    "        img[dy:, :] = 0\n",
    "    if dx>0:\n",
    "        img[:, :dx] = 0\n",
    "    elif dx<0:\n",
    "        img[:, dx:] = 0\n",
    "    return img\n",
    "\n",
    "def hologram_effect(img):\n",
    "    # add a blue tint\n",
    "    holo = cv2.applyColorMap(img, cv2.COLORMAP_WINTER)\n",
    "    # add a halftone effect\n",
    "    bandLength, bandGap = 2, 3\n",
    "    for y in range(holo.shape[0]):\n",
    "        if y % (bandLength+bandGap) < bandLength:\n",
    "            holo[y,:,:] = holo[y,:,:] * np.random.uniform(0.1, 0.3)\n",
    "    # add some ghosting\n",
    "    holo_blur = cv2.addWeighted(holo, 0.2, shift_image(holo.copy(), 5, 5), 0.8, 0)\n",
    "    holo_blur = cv2.addWeighted(holo_blur, 0.4, shift_image(holo.copy(), -5, -5), 0.6, 0)\n",
    "    # combine with the original color, oversaturated\n",
    "    out = cv2.addWeighted(img, 0.5, holo_blur, 0.6, 0)\n",
    "    return out\n",
    "\n",
    "def get_frame(cap, background_scaled):\n",
    "    _, frame = cap.read()\n",
    "    # fetch the mask with retries (the app needs to warmup and we're lazy)\n",
    "    # e v e n t u a l l y c o n s i s t e n t\n",
    "    mask = None\n",
    "    while mask is None:\n",
    "        try:\n",
    "            mask = get_mask(frame)\n",
    "        except requests.RequestException:\n",
    "            print(\"mask request failed, retrying\")\n",
    "    mask = post_process_mask(mask)\n",
    "#     frame = hologram_effect(frame)\n",
    "    inv_mask = 1-mask\n",
    "    for c in range(frame.shape[2]):\n",
    "        frame[:,:,c] = frame[:,:,c]*mask + background_scaled[:,:,c]*inv_mask\n",
    "#     for c in range(frame.shape[2]):\n",
    "#         temp = cv2.resize(frame[:,:,c],(50,50),interpolation=cv2.INTER_NEAREST)\n",
    "#         temp = cv2.resize(temp,(640,480),interpolation=cv2.INTER_NEAREST )\n",
    "#         frame[:,:,c] = temp*mask + background_scaled[:,:,c]*inv_mask\n",
    "#     for c in range(frame.shape[2]):\n",
    "#         temp = cv2.resize(frame[:,:,c],(30,30),interpolation=cv2.INTER_NEAREST)\n",
    "#         temp = cv2.resize(temp,(640,480),interpolation=cv2.INTER_NEAREST )\n",
    "#         frame[:,:,c] = temp*mask + frame[:,:,c]*inv_mask\n",
    "#     frame2 = cv2.cvtColor(frame,cv2.COLOR_BGR2HSV)\n",
    "#     for c in range(frame.shape[2]):\n",
    "#         temp = cv2.resize(frame2[:,:,c],(30,30),interpolation=cv2.INTER_NEAREST)\n",
    "#         temp = cv2.resize(temp,(640,480),interpolation=cv2.INTER_NEAREST )\n",
    "#         if c == 1:\n",
    "#             temp = temp*1.5\n",
    "#         if c == 2:\n",
    "#             temp = temp*0.5\n",
    "#         frame2[:,:,c] = temp*mask + frame2[:,:,c]*inv_mask\n",
    "#     frame = cv2.cvtColor(frame2,cv2.COLOR_HSV2BGR)\n",
    "\n",
    "\n",
    "\n",
    "    return frame\n",
    "\n",
    "\n",
    "\n",
    "# url = \"https://www.youtube.com/watch?v=nc5YHodcXpM\"\n",
    "# video = pafy.new(url)\n",
    "# streams = video.allstreams\n",
    "# name_of_qualities = [str(s) for s in streams]\n",
    "# for ind in range(len(name_of_qualities)):\n",
    "#     print(str(ind) + '.', name_of_qualities[ind])\n",
    "# chosen_quality_ind = input(\"Choose quality:\")\n",
    "# our_live_stream = streams[int(chosen_quality_ind)]\n",
    "# bg_cap = cv2.VideoCapture(our_live_stream.url)\n",
    "\n",
    "\n",
    "bg_cap = cv2.VideoCapture(\"bg/beach.mp4\")\n",
    "bg_cap.set(cv2.CAP_PROP_POS_FRAMES, 0)\n",
    "print(int(bg_cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "\n",
    "\n",
    "# def getFrame(frame_nr):\n",
    "#     global video\n",
    "#     video.set(cv2.CAP_PROP_POS_FRAMES, frame_nr)\n",
    "# nr_of_frames = int(bg_cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "# cv2.namedWindow(\"Video\")\n",
    "# cv2.createTrackbar(\"Frame\", \"Video\", 0,nr_of_frames,getFrame)\n",
    "# cv2.setTrackbarPos(\"Frame\",\"Video\", int(bg_cap.get(cv2.CAP_PROP_POS_FRAMES)))\n",
    "\n",
    "\n",
    "# setup access to the *real* webcam\n",
    "cap = cv2.VideoCapture('/dev/video0')\n",
    "height, width = 480, 640\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)\n",
    "cap.set(cv2.CAP_PROP_FPS, 60)\n",
    "\n",
    "# setup the fake camera\n",
    "fake = pyfakewebcam.FakeWebcam('/dev/video2', width, height)\n",
    "\n",
    "# load the virtual background\n",
    "background = cv2.imread(\"bg/star-wars-backgrounds-12-1.jpg\")\n",
    "background_scaled = cv2.resize(background, (width, height))\n",
    "cps = CountsPerSec().start()\n",
    "# frames forever\n",
    "while True:\n",
    "    \n",
    "    ret,background_scaled = bg_cap.read()\n",
    "    background_scaled = cv2.resize(background_scaled,(width,height))\n",
    "    frame = get_frame(cap, background_scaled)\n",
    "    # fake webcam expects RGB\n",
    "    frame = cv2.flip(frame,1)\n",
    "    frame = putIterationsPerSec(frame,cps.countsPerSec()) \n",
    "    cps.increment()\n",
    "    cv2.imshow(\"test\",frame)\n",
    "    frame = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)\n",
    "    fake.schedule_frame(frame)\n",
    "    keyboard = cv2.waitKey(1)\n",
    "    if keyboard == ord('q') or keyboard == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyVoiceChanger.1.5.0https://github.com/juancarlospaco/pyvoicechanger#pyvoicechanger\n",
      "Voice Deformation Value: 300\n",
      "Voice Deformation Command: play -q -V0 \"|rec -q -V0 -n -d -R riaa bend pitch 300 \"\n",
      "Minimizing Main Window to System TrayIcon now...\n",
      "Voice Deformation Value: 600\n",
      "Voice Deformation Command: play -q -V0 \"|rec -q -V0 -n -d -R riaa bend pitch 600 \"\n",
      "Minimizing Main Window to System TrayIcon now...\n",
      "Voice Deformation Value: -800\n",
      "Voice Deformation Command: play -q -V0 \"|rec -q -V0 -n -d -R riaa bend pitch -800 \"\n",
      "Minimizing Main Window to System TrayIcon now...\n",
      "Voice Deformation Value: 1000\n",
      "Voice Deformation Command: play -q -V0 \"|rec -q -V0 -n -d -R riaa bend pitch 1000 \"\n",
      "Minimizing Main Window to System TrayIcon now...\n",
      "Voice Deformation Value: 1400\n",
      "Voice Deformation Command: play -q -V0 \"|rec -q -V0 -n -d -R riaa bend pitch 1400 \"\n",
      "Minimizing Main Window to System TrayIcon now...\n",
      "Voice Deformation Value: 2000\n",
      "Voice Deformation Command: play -q -V0 \"|rec -q -V0 -n -d -R riaa bend pitch 2000 \"\n",
      "Minimizing Main Window to System TrayIcon now...\n",
      "Voice Deformation Value: -1000\n",
      "Voice Deformation Command: play -q -V0 \"|rec -q -V0 -n -d -R riaa bend pitch -1000 \"\n",
      "Minimizing Main Window to System TrayIcon now...\n",
      "Voice Deformation Value: -1000\n",
      "Voice Deformation Command: play -q -V0 \"|rec -q -V0 -n -d -R riaa bend pitch -1000 \"\n",
      "Minimizing Main Window to System TrayIcon now...\n",
      "Voice Deformation Value: -800\n",
      "Voice Deformation Command: play -q -V0 \"|rec -q -V0 -n -d -R riaa bend pitch -800 \"\n",
      "Minimizing Main Window to System TrayIcon now...\n",
      "Voice Deformation Value: -600\n",
      "Voice Deformation Command: play -q -V0 \"|rec -q -V0 -n -d -R riaa bend pitch -600 \"\n",
      "Minimizing Main Window to System TrayIcon now...\n",
      "Voice Deformation Value: -300\n",
      "Voice Deformation Command: play -q -V0 \"|rec -q -V0 -n -d -R riaa bend pitch -300 \"\n",
      "Minimizing Main Window to System TrayIcon now...\n",
      "Voice Deformation Value: 100\n",
      "Voice Deformation Command: play -q -V0 \"|rec -q -V0 -n -d -R riaa bend pitch 100 \"\n",
      "Minimizing Main Window to System TrayIcon now...\n",
      "Voice Deformation Value: 300\n",
      "Voice Deformation Command: play -q -V0 \"|rec -q -V0 -n -d -R riaa bend pitch 300 \"\n",
      "Minimizing Main Window to System TrayIcon now...\n",
      "Voice Deformation Value: 700\n",
      "Voice Deformation Command: play -q -V0 \"|rec -q -V0 -n -d -R riaa bend pitch 700 \"\n",
      "Minimizing Main Window to System TrayIcon now...\n"
     ]
    }
   ],
   "source": [
    "#!/usr/bin/env python3\n",
    "# -*- coding: utf-8 -*-\n",
    "\n",
    "\n",
    "\"\"\"PyVoiceChanger.\"\"\"\n",
    "\n",
    "\n",
    "import sys\n",
    "from subprocess import call\n",
    "from time import sleep\n",
    "\n",
    "from PyQt5.QtCore import QProcess, Qt, QTimer\n",
    "from PyQt5.QtGui import QColor, QCursor, QIcon\n",
    "from PyQt5.QtWidgets import (QApplication, QDial, QGraphicsDropShadowEffect,\n",
    "                             QGroupBox, QLabel, QMainWindow, QMenu,\n",
    "                             QShortcut, QSystemTrayIcon, QVBoxLayout)\n",
    "\n",
    "\n",
    "__version__ = '1.5.0'\n",
    "__license__ = ' GPLv3+ LGPLv3+ '\n",
    "__author__ = ' juancarlos '\n",
    "__email__ = ' juancarlospaco@gmail.com '\n",
    "__url__ = 'https://github.com/juancarlospaco/pyvoicechanger#pyvoicechanger'\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "sys.dont_write_bytecode = True\n",
    "\n",
    "\n",
    "class MainWindow(QMainWindow):\n",
    "\n",
    "    \"\"\"Voice Changer main window.\"\"\"\n",
    "\n",
    "    def __init__(self, parent=None):\n",
    "        super(MainWindow, self).__init__()\n",
    "        self.statusBar().showMessage(\"Move Dial to Deform Microphone Voice !.\")\n",
    "        self.setWindowTitle(__doc__)\n",
    "        self.setMinimumSize(240, 240)\n",
    "        self.setMaximumSize(480, 480)\n",
    "        self.resize(self.minimumSize())\n",
    "        self.setWindowIcon(QIcon.fromTheme(\"audio-input-microphone\"))\n",
    "        self.tray = QSystemTrayIcon(self)\n",
    "        self.center()\n",
    "        QShortcut(\"Ctrl+q\", self, activated=lambda: self.close())\n",
    "        self.menuBar().addMenu(\"&File\").addAction(\"Quit\", lambda: exit())\n",
    "        self.menuBar().addMenu(\"Sound\").addAction(\n",
    "            \"STOP !\", lambda: call('killall rec', shell=True))\n",
    "        windowMenu = self.menuBar().addMenu(\"&Window\")\n",
    "        windowMenu.addAction(\"Hide\", lambda: self.hide())\n",
    "        windowMenu.addAction(\"Minimize\", lambda: self.showMinimized())\n",
    "        windowMenu.addAction(\"Maximize\", lambda: self.showMaximized())\n",
    "        windowMenu.addAction(\"Restore\", lambda: self.showNormal())\n",
    "        windowMenu.addAction(\"FullScreen\", lambda: self.showFullScreen())\n",
    "        windowMenu.addAction(\"Center\", lambda: self.center())\n",
    "        windowMenu.addAction(\"Top-Left\", lambda: self.move(0, 0))\n",
    "        windowMenu.addAction(\"To Mouse\", lambda: self.move_to_mouse_position())\n",
    "        # widgets\n",
    "        group0 = QGroupBox(\"Voice Deformation\")\n",
    "        self.setCentralWidget(group0)\n",
    "        self.process = QProcess(self)\n",
    "        self.process.error.connect(\n",
    "            lambda: self.statusBar().showMessage(\"Info: Process Killed\", 5000))\n",
    "        self.control = QDial()\n",
    "        self.control.setRange(-10, 20)\n",
    "        self.control.setSingleStep(5)\n",
    "        self.control.setValue(0)\n",
    "        self.control.setCursor(QCursor(Qt.OpenHandCursor))\n",
    "        self.control.sliderPressed.connect(\n",
    "            lambda: self.control.setCursor(QCursor(Qt.ClosedHandCursor)))\n",
    "        self.control.sliderReleased.connect(\n",
    "            lambda: self.control.setCursor(QCursor(Qt.OpenHandCursor)))\n",
    "        self.control.valueChanged.connect(\n",
    "            lambda: self.control.setToolTip(f\"<b>{self.control.value()}\"))\n",
    "        self.control.valueChanged.connect(\n",
    "            lambda: self.statusBar().showMessage(\n",
    "                f\"Voice deformation: {self.control.value()}\", 5000))\n",
    "        self.control.valueChanged.connect(self.run)\n",
    "        self.control.valueChanged.connect(lambda: self.process.kill())\n",
    "        # Graphic effect\n",
    "        self.glow = QGraphicsDropShadowEffect(self)\n",
    "        self.glow.setOffset(0)\n",
    "        self.glow.setBlurRadius(99)\n",
    "        self.glow.setColor(QColor(99, 255, 255))\n",
    "        self.control.setGraphicsEffect(self.glow)\n",
    "        self.glow.setEnabled(False)\n",
    "        # Timer to start\n",
    "        self.slider_timer = QTimer(self)\n",
    "        self.slider_timer.setSingleShot(True)\n",
    "        self.slider_timer.timeout.connect(self.on_slider_timer_timeout)\n",
    "        # an icon and set focus\n",
    "        QLabel(self.control).setPixmap(\n",
    "            QIcon.fromTheme(\"audio-input-microphone\").pixmap(32))\n",
    "        self.control.setFocus()\n",
    "        QVBoxLayout(group0).addWidget(self.control)\n",
    "        self.menu = QMenu(__doc__)\n",
    "        self.menu.addAction(__doc__).setDisabled(True)\n",
    "        self.menu.setIcon(self.windowIcon())\n",
    "        self.menu.addSeparator()\n",
    "        self.menu.addAction(\n",
    "            \"Show / Hide\",\n",
    "            lambda: self.hide() if self.isVisible() else self.showNormal())\n",
    "        self.menu.addAction(\"STOP !\", lambda: call('killall rec', shell=True))\n",
    "        self.menu.addSeparator()\n",
    "        self.menu.addAction(\"Quit\", lambda: exit())\n",
    "        self.tray.setContextMenu(self.menu)\n",
    "        self.make_trayicon()\n",
    "\n",
    "    def run(self):\n",
    "        \"\"\"Run/Stop the QTimer.\"\"\"\n",
    "        if self.slider_timer.isActive():\n",
    "            self.slider_timer.stop()\n",
    "        self.glow.setEnabled(True)\n",
    "        call('killall rec ; killall play', shell=True)\n",
    "        self.slider_timer.start(3000)\n",
    "\n",
    "    def on_slider_timer_timeout(self):\n",
    "        \"\"\"Run subprocess to deform voice.\"\"\"\n",
    "        self.glow.setEnabled(False)\n",
    "        value = int(self.control.value()) * 100\n",
    "        command = f'play -q -V0 \"|rec -q -V0 -n -d -R riaa bend pitch {value} \"'\n",
    "        print(f\"Voice Deformation Value: {value}\")\n",
    "        print(f\"Voice Deformation Command: {command}\")\n",
    "        self.process.start(command)\n",
    "        if self.isVisible():\n",
    "            self.statusBar().showMessage(\"Minimizing to System TrayIcon\", 3000)\n",
    "            print(\"Minimizing Main Window to System TrayIcon now...\")\n",
    "            sleep(3)\n",
    "            self.hide()\n",
    "\n",
    "    def center(self):\n",
    "        \"\"\"Center Window on the Current Screen,with Multi-Monitor support.\"\"\"\n",
    "        window_geometry = self.frameGeometry()\n",
    "        mousepointer_position = QApplication.desktop().cursor().pos()\n",
    "        screen = QApplication.desktop().screenNumber(mousepointer_position)\n",
    "        centerPoint = QApplication.desktop().screenGeometry(screen).center()\n",
    "        window_geometry.moveCenter(centerPoint)\n",
    "        self.move(window_geometry.topLeft())\n",
    "\n",
    "    def move_to_mouse_position(self):\n",
    "        \"\"\"Center the Window on the Current Mouse position.\"\"\"\n",
    "        window_geometry = self.frameGeometry()\n",
    "        window_geometry.moveCenter(QApplication.desktop().cursor().pos())\n",
    "        self.move(window_geometry.topLeft())\n",
    "\n",
    "    def make_trayicon(self):\n",
    "        \"\"\"Make a Tray Icon.\"\"\"\n",
    "        if self.windowIcon() and __doc__:\n",
    "            self.tray.setIcon(self.windowIcon())\n",
    "            self.tray.setToolTip(__doc__)\n",
    "            self.tray.activated.connect(\n",
    "                lambda: self.hide() if self.isVisible()\n",
    "                else self.showNormal())\n",
    "            return self.tray.show()\n",
    "\n",
    "\n",
    "###############################################################################\n",
    "\n",
    "\n",
    "def main():\n",
    "    \"\"\"Main Loop.\"\"\"\n",
    "    print(__doc__ + __version__ + __url__)\n",
    "    application = QApplication(sys.argv)\n",
    "    application.setApplicationName(\"pyvoicechanger\")\n",
    "    application.setOrganizationName(\"pyvoicechanger\")\n",
    "    application.setOrganizationDomain(\"pyvoicechanger\")\n",
    "    application.setWindowIcon(QIcon.fromTheme(\"audio-input-microphone\"))\n",
    "    application.aboutToQuit.connect(\n",
    "        lambda: call('killall rec ; killall play', shell=True))\n",
    "    mainwindow = MainWindow()\n",
    "    mainwindow.show()\n",
    "    sys.exit(application.exec_())\n",
    "\n",
    "\n",
    "if __name__ in '__main__':\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import pafy\n",
    "\n",
    "url = \"https://www.youtube.com/watch?v=GIZmiXV2swI\"\n",
    "video = pafy.new(url)\n",
    "best = video.getbest(preftype=\"mp4\")\n",
    "\n",
    "cap = cv2.VideoCapture()\n",
    "cap.open(best.url)\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    cv2.imshow(\"test\",frame)\n",
    "   \n",
    "    keyboard = cv2.waitKey(30)\n",
    "    if keyboard == ord('q') or keyboard == 27:\n",
    "        break\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
